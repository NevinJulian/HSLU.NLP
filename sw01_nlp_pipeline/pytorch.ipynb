{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47b1b6f",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "In this exercise, we will look at some basic functionality of PyTorch. Your are free to use other DL frameworks for your exercises and your project. However, the master solutions and code examples will be in PyTorch.\n",
    "\n",
    "The [PyTorch documentation](https://pytorch.org/docs/stable/index.html) offers information on its functionality. A lot of the time, your specific question will also have been asked on the [PyTorch Forum](https://discuss.pytorch.org/), often with competent answers by the core developers (Google will find the relevant thread for you).\n",
    "\n",
    "First, we have to install PyTorch. We will install the basic version for this exercise. For your project, if you want to run on a GPU, you'll have to make sure to have a PyTorch version installed that is compatible with the CUDA version of your NVIDIA drivers. PyTorch has an [installation guide](https://pytorch.org/get-started/locally/) that will help you with getting the right version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1efca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.2.3 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
      "ydata-profiling 4.12.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U numpy\n",
    "%pip install -q torch ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c05320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14248da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Number of GPUs: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec5791",
   "metadata": {},
   "source": [
    "## Tensor operations\n",
    "Most of PyTorch's operations have the same name as in NumPy. The basic object for storing data is the `torch.tensor`, the equivalent of the `np.array`. With the help of the [Tensor tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html), do the following:\n",
    "\n",
    "- Create a `torch.tensor` with the elements `[[1, 2], [3, 4]]`\n",
    "- Create a tensor of ones/zeros with the same shape and dtype\n",
    "- Create a random tensor of the same shape\n",
    "- Print the tensor's shape, data type and device\n",
    "- Try to move it to the GPU\n",
    "- For Mac users: Try to move it to [MPS](https://pytorch.org/docs/stable/notes/mps.html)\n",
    "- Check out indexing/slicing operations, and how you can assign values to a slice.\n",
    "- Combine tensors with `torch.cat` and `torch.stack`. What are the differences?\n",
    "- Multiply tensors, element-wise and with matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90229fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from list: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0, 0],\n",
      "        [0, 0]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.3485, 0.9696],\n",
      "        [0.7514, 0.5897]]) \n",
      "\n",
      "Shape of tensor: torch.Size([2, 2])\n",
      "Data type of tensor: torch.int64\n",
      "Device tensor is stored on: cpu\n",
      "Device tensor is stored on: cuda:0\n",
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(f\"Tensor from list: \\n {x_data} \\n\")\n",
    "\n",
    "ones = torch.ones_like(x_data)\n",
    "zeros = torch.zeros_like(x_data)\n",
    "\n",
    "print(f\"Ones Tensor: \\n {ones} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros} \\n\")\n",
    "\n",
    "rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {rand} \\n\")\n",
    "\n",
    "print(f\"Shape of tensor: {x_data.shape}\")\n",
    "print(f\"Data type of tensor: {x_data.dtype}\")\n",
    "print(f\"Device tensor is stored on: {x_data.device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x_data = x_data.to('cuda')\n",
    "\n",
    "print(f\"Device tensor is stored on: {x_data.device}\")\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3cc76c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "t2 = torch.stack([tensor, tensor, tensor])\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026f25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.) 12.0\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "#Elementwise multiplication (Tensors of same shape)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "\n",
    "print(agg, agg_item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36d91f",
   "metadata": {},
   "source": [
    "## Neural Network Basics\n",
    "Solve the followings tasks with the help of the [Neural networks tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
    "\n",
    "The `nn.Module` is the basic class for layers, networks and models. All parameters of an `nn.Module` are automatically discovered by PyTorch and updated by back-propagation.\n",
    "\n",
    "First, define a neural network (as a subclass of `nn.Module`) with two linear layers and a ReLU non-linearity in between. Make the input, output, and inner dimensions parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5284525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66e191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=10, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, inner_dim=10):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, inner_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(inner_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "dim_in=40\n",
    "dim_out=20\n",
    "\n",
    "net=NeuralNetwork(dim_in, dim_out)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eae143",
   "metadata": {},
   "source": [
    "Move the entire network to the GPU/MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f976d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device before moving: cuda:0\n",
      "Device after moving: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device before moving: {net.fc1.weight.device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.to('cuda')\n",
    "\n",
    "print(f\"Device after moving: {next(net.parameters()).is_cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22867b",
   "metadata": {},
   "source": [
    "Print the parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e3383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Layer: fc1.weight | shape: torch.Size([10, 40])\n",
      "Layer: fc1.bias | shape: torch.Size([10])\n",
      "Layer: fc2.weight | shape: torch.Size([20, 10])\n",
      "Layer: fc2.bias | shape: torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"Layer: {name} | shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f403132",
   "metadata": {},
   "source": [
    "Run a single forward-pass with a random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3370725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n",
      "tensor([[-0.1239,  0.0158,  0.2417,  0.1462, -0.2419,  0.1031,  0.3157,  0.0172,\n",
      "         -0.1190, -0.3693,  0.1668,  0.2677,  0.3859, -0.2153, -0.1292, -0.3454,\n",
      "         -0.0346, -0.1634,  0.2963,  0.1170],\n",
      "        [ 0.0339, -0.0390,  0.3529,  0.1703, -0.3415, -0.0408,  0.3265,  0.0882,\n",
      "         -0.0315, -0.2572,  0.1637,  0.2843,  0.3369, -0.2198, -0.0736, -0.3532,\n",
      "         -0.2178, -0.0418,  0.3460,  0.1581],\n",
      "        [ 0.0649, -0.0210,  0.1527,  0.1029, -0.4310, -0.0038,  0.4565,  0.0370,\n",
      "         -0.0676, -0.2702,  0.2059,  0.2711,  0.5534, -0.3832, -0.1581, -0.3982,\n",
      "         -0.2693, -0.0551,  0.2896,  0.1580],\n",
      "        [ 0.0857, -0.0235,  0.1275,  0.1037, -0.3651,  0.0206,  0.4146,  0.0417,\n",
      "         -0.1268, -0.2121,  0.1795,  0.3226,  0.4662, -0.3260, -0.1705, -0.3650,\n",
      "         -0.2001, -0.0411,  0.3368,  0.1932],\n",
      "        [-0.0008,  0.0184,  0.1799,  0.2713, -0.4501, -0.0443,  0.4466,  0.0745,\n",
      "         -0.0783, -0.3144,  0.3061,  0.3160,  0.4546, -0.2847, -0.0849, -0.4028,\n",
      "         -0.2653, -0.0442,  0.2239,  0.1073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([5, 20])\n",
      "tensor([[-0.1239,  0.0158,  0.2417,  0.1462, -0.2419,  0.1031,  0.3157,  0.0172,\n",
      "         -0.1190, -0.3693,  0.1668,  0.2677,  0.3859, -0.2153, -0.1292, -0.3454,\n",
      "         -0.0346, -0.1634,  0.2963,  0.1170],\n",
      "        [ 0.0339, -0.0390,  0.3529,  0.1703, -0.3415, -0.0408,  0.3265,  0.0882,\n",
      "         -0.0315, -0.2572,  0.1637,  0.2843,  0.3369, -0.2198, -0.0736, -0.3532,\n",
      "         -0.2178, -0.0418,  0.3460,  0.1581],\n",
      "        [ 0.0649, -0.0210,  0.1527,  0.1029, -0.4310, -0.0038,  0.4565,  0.0370,\n",
      "         -0.0676, -0.2702,  0.2059,  0.2711,  0.5534, -0.3832, -0.1581, -0.3982,\n",
      "         -0.2693, -0.0551,  0.2896,  0.1580],\n",
      "        [ 0.0857, -0.0235,  0.1275,  0.1037, -0.3651,  0.0206,  0.4146,  0.0417,\n",
      "         -0.1268, -0.2121,  0.1795,  0.3226,  0.4662, -0.3260, -0.1705, -0.3650,\n",
      "         -0.2001, -0.0411,  0.3368,  0.1932],\n",
      "        [-0.0008,  0.0184,  0.1799,  0.2713, -0.4501, -0.0443,  0.4466,  0.0745,\n",
      "         -0.0783, -0.3144,  0.3061,  0.3160,  0.4546, -0.2847, -0.0849, -0.4028,\n",
      "         -0.2653, -0.0442,  0.2239,  0.1073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "x= torch.rand(batch_size, dim_in)\n",
    "\n",
    "try:\n",
    "    y = net(x)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "if torch.cuda.is_available():\n",
    "    x=x.to('cuda')\n",
    "    y = net(x)\n",
    "    print(y)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d2cb7",
   "metadata": {},
   "source": [
    "Define a `nn.MSELoss` and a random target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1983de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39785fbe",
   "metadata": {},
   "source": [
    "Compute the loss and run backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5cc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e278bd02",
   "metadata": {},
   "source": [
    "Update the parameters of your network with a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe16c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "927bd19f",
   "metadata": {},
   "source": [
    "Use the `AdamOptimizer` instead to update your parameters (see the [torch.optim documentation](https://pytorch.org/docs/stable/optim.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054db4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
